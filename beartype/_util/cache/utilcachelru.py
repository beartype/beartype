#!/usr/bin/env python3
# --------------------( LICENSE                           )--------------------
# Copyright (c) 2014-2021 Cecil Curry.
# See "LICENSE" for further details.

"""
**Beartype Least Recently Used (LRU) caching utilities.**

This private submodule implements supplementary cache-specific utility
functions required by various :mod:`beartype` facilities, including callables
generated by the :func:`beartype.beartype` decorator.

This private submodule is *not* intended for importation by downstream callers.
"""
# ....................{ IMPORTS                           }....................
from beartype.roar import _BeartypeUtilLRUCacheException
from threading import Lock


# ....................{ CLASSES                           }....................
class LRUCacheStrong(dict):
    """
    **Thread-safe strong Least Recently Used (LRU) cache** (i.e., a mapping
    from strong references to arbitrary keys onto strong references to
    arbitrary values, limited to some maximum capacity by implicitly and
    thread-safely removing the least recently accessed key-value pair from
    this mapping upon adding a new key-value pair that would cause the
    size of this mapping to exceed the maximum capacity).

    Design
    ------
    Conventional LRU cache implementations typically employ weak references
    for memory safety. Implementations employing strong references invite
    memory leaks due to the deallocation dependency created by the referent;
    While a strong reference is cached, the garbage collector cannot deallocate
    the referenced Object's memory.

    This cache intentionally employs strong references for the persistence of
    these **cache-only objects** (i.e., objects *only* referenced by this cache)
    across calls to Callables decorated by the :func:`beartype.beartype`
    decorator. Since cache-only objects are referenced only by this cache
    rather than by an external parent object, caching the Object using a weak
    reference would result in *no* strong referents. In turn, the CPython
    garbage collector would immediately collect the Object along with all other
    short-lived first generation objects. The standard example of a cache-only
    object is a container iterator (e.g., the items view returned by :meth:`dict.items`).

    Note that the equivalent LRU cache employing weak references to keys and/or
    values may be trivially implemented by inheriting from the standard
    :class:`weakref.WeakKeyDictionary` or :class:`weakref.WeakValueDictionary`
    classes rather than the builtin :class:`dict` type instead.

    Attributes
    ----------
    _size : int
        **Cache capacity** (i.e., maximum positive number of items to cache).
    _thread_lock : Lock
        **Reentrant instance-specific thread lock** (i.e., low-level thread
        locking mechanism implemented as a highly efficient C extension,
        defined as an instance variable for non-reentrant reuse by the public
        API of this class). Although CPython, the canonical Python interpreter,
        *does* prohibit conventional multithreading via its Global Interpreter
        Lock (GIL), CPython still coercively preempts long-running threads at
        arbitrary execution points. Ergo, multithreading concerns are *not*
        safely ignorable -- even under CPython.
    """

    # ..................{ CLASS VARIABLES                   }..................
    # Slot all instance variables defined on this object to minimize the time
    # complexity of both reading and writing variables across frequently called
    # cache dunder methods. Slotting has been shown to reduce read and write
    # costs by approximately ~10%, which is non-trivial.
    __slots__ = ('_size', '_thread_lock',)

    # ..................{ DUNDERS                           }..................
    def __init__(self, size: int) -> None:
        """
        Initialize this cache to the empty cache with the passed capacity.

        Parameters
        ----------
        size : int
            **Cache capacity** (i.e., maximum positive number of items memoized).

        Raises
        ------
        _BeartypeUtilLRUCacheException
            If this capacity is:

            * *Not* an integer.
            * A **non-positive integer** (i.e., either negative or zero).
        """
        if not isinstance(size, int):
            raise _BeartypeUtilLRUCacheException(
                f'LRU cache capacity {repr(size)} not integer.')

        elif size <= 0:
            raise _BeartypeUtilLRUCacheException(
                f'LRU cache capacity {size} not positive.')

        # Initialize an empty dictionary.
        super().__init__()

        self._size = size
        self._thread_lock = Lock()

    def __getitem__(self,
                    key: 'Hashable',
                    # Superclass methods efficiently localized as default parameters.
                    __dict_delitem=dict.__delitem__,
                    __dict_getitem=dict.__getitem__,
                    __dict_setitem=dict.__setitem__,
                    ) -> object:
        """
        Return the associated cached value - raise an exception if None exists.

        Specifically, this method (in order):

        * If this key has *not* been recently cached, raises the standard
          :class:`KeyError` exception.
        * Else:

          #. Gets the value previously cached under this key.
          #. Prioritizes this key by removing and re-adding this key back to
             the tail of this cache.
          #. Returns this value.

        Parameters
        ----------
        key : Hashable
            Arbitrary hashable key to retrieve the cached value of.

        Returns
        ----------
        object
            Arbitrary value recently cached under this key.

        Raises
        ----------
        TypeError
            If this key is unhashable.
        KeyError
            If this key is not cached
        """

        # In a thread-safe manner...
        with self._thread_lock:
            # Get cached value - raising KeyError if None exists
            value = __dict_getitem(self, key)

            # Reset key priority
            __dict_delitem(self, key)
            __dict_setitem(self, key, value)

            # Return this value
            return value

    def __setitem__(self,
                    key: 'Hashable',
                    value: object,

                    # Superclass methods efficiently localized as default parameters.
                    __dict_hasitem=dict.__contains__,
                    __dict_delitem=dict.__delitem__,
                    __dict_setitem=dict.__setitem__,
                    __dict_iter=dict.__iter__,
                    __dict_len=dict.__len__,
                    ) -> None:
        """
        Cache the passed key-value pair while preserving LRU constraints.

        Specifically, this method (in order):

        #. If this key has already been cached, prioritize this key by removing
           this key from this cache.
        #. (Re-)add this key to the tail of this cache.
        #. If adding this key caused this cache to exceed its maximum capacity,
           silently remove the first (and thus least recently used) key-value
           pair from this cache.

        Parameters
        ----------
        key : Hashable
            Arbitrary hashable key to cache this value to.
        value : object
            Arbitrary value to be cached under this key.

        Raises
        ----------
        TypeError
            If this key is unhashable.
        """

        # In a thread-safe manner...
        with self._thread_lock:

            # Reset this key's priority
            if __dict_hasitem(self, key):
                __dict_delitem(self, key)

            # (Re-)add this key back to the end of this cache.
            __dict_setitem(self, key, value)

            if __dict_len(self) > self._size:
                # Silently remove the least recently used item from this cache.
                __dict_delitem(self, next(__dict_iter(self)))

    def __contains__(self,
                     key: 'Hashable',
                     # Superclass methods efficiently localized as default parameters.
                     __dict_contains=dict.__contains__,
                     __self_getitem__=__getitem__,
                     ) -> bool:
        """
        Returns ``True`` and resets this key's priority if this key is cached.

        Parameters
        ----------
        key : Hashable
            Arbitrary hashable key to check the existence of in this cache.

        Returns
        ----------
        bool
            ``True`` only if this key has been recently cached.

        Raises
        ----------
        TypeError
            If this key is unhashable.
        """
        # In a thread-safe manner...
        with self._thread_lock:
            if __dict_contains(self, key):
                # Reset this key's priority
                __self_getitem__(self, key)
                return True
            return False
